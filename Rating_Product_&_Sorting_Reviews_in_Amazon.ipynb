{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping for Competitor and Price Analysis\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "An online book retailer has identified lower sales in the \"Travel\" and \"Nonfiction\" categories. To address this, the company needs to scrape data from the competitor's website, [Books to Scrape](https://books.toscrape.com/), specifically from the \"Travel\" and \"Nonfiction\" categories. The objective is to collect detailed information about the books in these categories for competitor and price analysis.\n",
    "\n",
    "## Project Tasks\n",
    "\n",
    "### Task 1: Configure and Launch the Browser\n",
    "\n",
    "1. **Set Up Chrome Options**\n",
    "   Use Selenium's WebDriver class to define a ChromeOptions object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a4c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Set Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-popup-blocking\")\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "options.add_argument(\"--start-maximized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Start ChromeDriver Service**\n",
    "   Initialize the ChromeDriver service with the path to the executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8a2f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service = Service(executable_path='path_to_your_chromedriver')\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Inspect and Scrape the Homepage\n",
    "\n",
    "1. **Open the Homepage**\n",
    "   Load the homepage and observe its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e2a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "SLEEP_TIME = 2\n",
    "\n",
    "driver.get(\"http://books.toscrape.com\")\n",
    "time.sleep(SLEEP_TIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Extract Category Links**\n",
    "   Write an XPath query to find elements for \"Travel\" and \"Nonfiction\" category links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7f1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_elements_xpath = \"//a[contains(text(), 'Travel') or contains(text(), 'Nonfiction')]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Scrape Category Links**\n",
    "   Find the elements using the XPath query and extract the category URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0098db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_elements = driver.find_elements(By.XPATH, category_elements_xpath)\n",
    "category_urls = [element.get_attribute('href') for element in category_elements]\n",
    "category_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Inspect and Scrape the Category Page\n",
    "\n",
    "1. **Extract Book Links from Category Page**\n",
    "   Write an XPath query to find book detail links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c2cda3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "book_elements_xpath = \"//div[@class='image_container']//a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Scrape Book Links**\n",
    "   Find and extract the book detail links from the category pages, including handling pagination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64d073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_PAGINATION = 3\n",
    "book_urls = []\n",
    "for i in range(1, MAX_PAGINATION + 1):\n",
    "    update_url = category_urls[1].replace(\"index\", f\"page-{i}\") if i > 1 else category_urls[1]\n",
    "    driver.get(update_url)\n",
    "    book_elements = driver.find_elements(By.XPATH, book_elements_xpath)\n",
    "    if not book_elements:\n",
    "        break\n",
    "    book_urls.extend([element.get_attribute('href') for element in book_elements])\n",
    "book_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Scrape Product Detail Pages\n",
    "\n",
    "1. **Extract Book Details**\n",
    "   For each book detail page, scrape the following information:\n",
    "   - Book Title\n",
    "   - Book Price\n",
    "   - Book Star Rating\n",
    "   - Book Description\n",
    "   - Product Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e2c0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def get_book_details(driver, book_url):\n",
    "    driver.get(book_url)\n",
    "    time.sleep(0.3)\n",
    "    content_div = driver.find_element(By.XPATH, \"//div[@class='content']\")\n",
    "    inner_html = content_div.get_attribute('innerHTML')\n",
    "    soup = BeautifulSoup(inner_html, 'html.parser')\n",
    "\n",
    "    book_name = soup.find('h1').get_text()\n",
    "    book_price = soup.find(\"p\", attrs={\"class\": \"price_color\"}).get_text()\n",
    "    regex = re.compile('^star-rating ')\n",
    "    book_star_count = soup.find(\"p\", attrs={\"class\": regex})[\"class\"][-1]\n",
    "    book_desc = soup.find(\"div\", attrs={\"id\": \"product_description\"}).find_next_sibling().get_text()\n",
    "\n",
    "    product_info = {}\n",
    "    table_rows = soup.find(\"table\").find_all(\"tr\")\n",
    "    for row in table_rows:\n",
    "        key = row.find(\"th\").get_text()\n",
    "        value = row.find(\"td\").get_text()\n",
    "        product_info[key] = value\n",
    "\n",
    "    return {\n",
    "        \"Name\": book_name,\n",
    "        \"Price\": book_price,\n",
    "        \"Stars\": book_star_count,\n",
    "        \"Description\": book_desc,\n",
    "        \"Product Information\": product_info\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Automate and Organize the Process\n",
    "\n",
    "1. **Function Implementation**\n",
    "   Define functions to automate the scraping and data collection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd4b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    # Set up and return the WebDriver instance\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--disable-popup-blocking\")\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    service = Service(executable_path='path_to_your_chromedriver')\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver\n",
    "\n",
    "def get_category_urls(driver):\n",
    "    category_elements_xpath = \"//a[contains(text(), 'Travel') or contains(text(), 'Nonfiction')]\"\n",
    "    category_elements = driver.find_elements(By.XPATH, category_elements_xpath)\n",
    "    category_urls = [element.get_attribute('href') for element in category_elements]\n",
    "    category_names = [element.text.strip() for element in category_elements]  # Kategori isimlerini de alıyoruz\n",
    "    return category_urls, category_names\n",
    "\n",
    "def get_book_urls(driver, category_url, max_pagination=3):\n",
    "    book_urls = []\n",
    "    for i in range(1, max_pagination + 1):\n",
    "        update_url = category_url if i == 1 else category_url.replace(\"index\", f\"page-{i}\")\n",
    "        driver.get(update_url)\n",
    "        time.sleep(0.3)\n",
    "        book_elements_xpath = \"//div[@class='image_container']//a\"\n",
    "        book_elements = driver.find_elements(By.XPATH, book_elements_xpath)\n",
    "        if not book_elements:\n",
    "            break\n",
    "        temp_urls = [element.get_attribute('href') for element in book_elements]\n",
    "        book_urls.extend(temp_urls)\n",
    "    return book_urls\n",
    "\n",
    "def scrape_books(driver):\n",
    "    driver.get(\"http://books.toscrape.com\")\n",
    "    category_urls, category_names = get_category_urls(driver)\n",
    "\n",
    "    all_books = []\n",
    "    for category_url, category_name in zip(category_urls, category_names):\n",
    "        book_urls = get_book_urls(driver, category_url)\n",
    "        for book_url in book_urls:\n",
    "            book_details = get_book_details(driver, book_url)\n",
    "            book_details['Category'] = category_name  # Kategori ismini de ekliyoruz\n",
    "            all_books.append(book_details)\n",
    "\n",
    "    import pandas as pd\n",
    "    # DataFrame oluşturma\n",
    "    df = pd.DataFrame(all_books)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Run the Scraping Process**\n",
    "   Use the functions to collect data and create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de4e9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = setup_driver()\n",
    "books_df = scrape_books(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "1. **Price vs. Star Ratings**\n",
    "   Create a scatter plot to visualize the relationship between book prices and star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532a7e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert star ratings to numerical values\n",
    "star_mapping = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "books_df['Stars'] = books_df['Stars'].map(star_mapping)\n",
    "\n",
    "# Convert price to float\n",
    "books_df['Price'] = books_df['Price'].replace('£', '', regex=True).astype(float)\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Price', y='Stars', data=books_df)\n",
    "plt.title('Book Prices vs. Star Ratings')\n",
    "plt.xlabel('Price (£)')\n",
    "plt.ylabel('Star Ratings')\n",
    "plt.legend(title='Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Price Distribution by Category**\n",
    "   Create a box plot to show price distribution by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089fc0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"Stars\", y='Price', data=books_df)\n",
    "plt.title('Price Distribution by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Price (£)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Distribution of Prices and Star Ratings**\n",
    "   Plot histograms for the distribution of prices and star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e848024a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Price distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(books_df['Price'], kde=True)\n",
    "plt.title('Price Distribution')\n",
    "plt.xlabel('Price (£)')\n",
    "\n",
    "# Star rating distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(books_df['Stars'], kde=True, bins=5)\n",
    "plt.title('Star Rating Distribution')\n",
    "plt.xlabel('Stars')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Close the Browser**\n",
    "   After completing the scraping and analysis, close the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d540d98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
